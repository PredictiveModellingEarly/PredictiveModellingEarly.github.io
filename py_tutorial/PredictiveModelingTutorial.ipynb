{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oZpJHlWqnvBf"
   },
   "source": [
    "# Predictive Modeling for Beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCNORrN0nvCB"
   },
   "source": [
    "In this tutorial, we will walk through the basics of predictive modeling and provide example code along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iy0E_YLKnvCD"
   },
   "source": [
    "### Table of Contents\n",
    "\n",
    "1. What is predictive modeling?\n",
    "2. The Learning Machine\n",
    "3. Training / Validation / Test Split\n",
    "4. The Predict Function\n",
    "5. The Correct Classification Rate (CCR) Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3z-utcBKnvCE"
   },
   "source": [
    "### 1. Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvZUESjAnvCF"
   },
   "source": [
    "In the past 15 years, hospitals have begun warehousing patient data, and large medical datasets are now available. The outcome (e.g., diagnosis, or death) for each patient is recorded. Other information about the patient that may be available includes demographic information, the medications prescribed to the patient, various physiological  measurements such as core body temperature and the heart rate, and the procedures ordered for the patient.\n",
    "\n",
    "We can use predictive modeling to build *models* that predict the outcomes for new patients by generalizing from existing data. That is because patients with similar demographics, physiological measurements, medical histories etc. are likely to have similar outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iVJnXRo9nvCG"
   },
   "source": [
    "A model uses a number of *predictor variables*. The predictor variables can be used to predict the *outcome variable*.\n",
    "\n",
    "Predictive modeling is a powerful tool that can be applied to a vast number of sectors. For example, businesses can use predictive modeling to analyze customer behavior data and predict how, for example, customers will react to a price change. Predictive models can be used to predict stock prices by using past stock market data. Political scientists use predictive modeling to predict the outcome of a new election in a country based on the current political and economic situation by using datasets that contain past electoral outcomes and the political and economic history of the country.\n",
    "\n",
    "Predictive models are almost never 100% accurate: they merely generalize patterns in the dataset to predict the most likely outcome for new situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8TSsNP3nvCH"
   },
   "source": [
    "#### Overview \n",
    "\n",
    "First, we'll discuss how to use what we call a *Learning Machine* to build a model. We will focus on predicting patient outcomes in the Intensive Care Unit (ICU). We'll show  how to generate three important subsets of our dataset: the *training set*, the *validation set*, and the *test set*. We'll then see how our `predict` function can predict the outcomes for new situations -- we will predict whether patients that the Learning Machine hasn't seen before will survive in the ICU. We'll then assess the model's performance by computing the *correct classification rate* (CCR) of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7GMs24KnvCJ"
   },
   "source": [
    "### 2. The Learning Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCXkmdaunvCK"
   },
   "source": [
    "<img src=\"LearningMachine.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLU7kzbFnvCK"
   },
   "source": [
    "We will perform predictive modeling using the Learning Machine (LM). The Learning Machine is an abstraction. We introduce it here to simplify the presentation.  Think of the LM as a function that takes in a dataset (which contains predictor variables as well as the outcomes for historical data) and produces a model that can predict the outcomes for new situations. The field of Machine Learning deals with building better LMs. Logistic Regression and Neural Networks are examples of LMs.\n",
    "\n",
    "Data is fed into the LM. The LM learns patterns from the data and spits out a model that the LM deems to be the best way of capturing the relationships in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2SsNuvKnvCL"
   },
   "source": [
    "Let's focus on predicting in-hospital patient deaths in the ICU. The data was collected in the ICU of the Beth Israel Deaconess Medical Center in Boston. We provide the data in `ICU_data.csv`. The dataset contains demographic and physiological variables that were collected for each patient during their stay in the ICU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCwop8t7nvCM"
   },
   "source": [
    "For more information on the dataset, check [this webpage](https://physionet.org/content/challenge-2012/1.0.0/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8jlA6idnvCM"
   },
   "source": [
    "Let's now get to the code. You will need the following libraries. We recommend installing the [Anaconda](https://www.anaconda.com/distribution/) Python distribution, which comes with all the packages that you need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctCzCEVtnvCO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import learningmachine as lm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzQQbOVynvCR"
   },
   "source": [
    "The following is part of the set-up process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNoENqVonvCS"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zHZOE3LnvCV"
   },
   "source": [
    "We will read in `ICU_data.csv` into Python (note that you can open `ICU_data.csv` in spreadsheet software such as Excel, or even with a text editor).\n",
    "\n",
    "When reading in the data, we will use the `Pandas` package. However, we will mostly not use `Pandas` in this tutorial: we will convert the data to a list-of-lists format almost right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "id": "8WgyT4DknvCW",
    "outputId": "65ef4772-6154-4454-b403-e70598f1c905"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ICU_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-O4CH3f_nvCa"
   },
   "source": [
    "We can display the first several rows of the dataset as follows. (Open the dataset in Excel or a text editor to confirm that the data was read in correctly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BjgCZb8KnvCa",
    "outputId": "c787631d-69f6-45c6-b551-496e6fd58896"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>FiO2</th>\n",
       "      <th>GCS</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HR</th>\n",
       "      <th>Height</th>\n",
       "      <th>K</th>\n",
       "      <th>MAP</th>\n",
       "      <th>NIDiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Urine</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>SAPS-I</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Length_of_stay</th>\n",
       "      <th>Survival</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>59.543420</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>M</td>\n",
       "      <td>118.239130</td>\n",
       "      <td>169.787227</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>81.055075</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>118.591225</td>\n",
       "      <td>37.658333</td>\n",
       "      <td>89.729730</td>\n",
       "      <td>138.100000</td>\n",
       "      <td>7.43250</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>351.063772</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>46.101449</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>5.956522</td>\n",
       "      <td>M</td>\n",
       "      <td>79.269231</td>\n",
       "      <td>169.787227</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>72.217391</td>\n",
       "      <td>55.296296</td>\n",
       "      <td>...</td>\n",
       "      <td>132.913043</td>\n",
       "      <td>36.466667</td>\n",
       "      <td>134.017937</td>\n",
       "      <td>111.592208</td>\n",
       "      <td>7.46875</td>\n",
       "      <td>14.96168</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>57.753623</td>\n",
       "      <td>0.549199</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>M</td>\n",
       "      <td>91.652174</td>\n",
       "      <td>175.300000</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>77.985507</td>\n",
       "      <td>58.260870</td>\n",
       "      <td>...</td>\n",
       "      <td>99.014493</td>\n",
       "      <td>37.634694</td>\n",
       "      <td>290.625000</td>\n",
       "      <td>85.772059</td>\n",
       "      <td>7.39800</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>351.063772</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>83.0</td>\n",
       "      <td>60.528090</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>11.533333</td>\n",
       "      <td>F</td>\n",
       "      <td>79.078652</td>\n",
       "      <td>169.787227</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>86.505618</td>\n",
       "      <td>69.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>132.280899</td>\n",
       "      <td>36.716667</td>\n",
       "      <td>113.829787</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>7.33750</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>59.0</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>9.454545</td>\n",
       "      <td>M</td>\n",
       "      <td>63.200000</td>\n",
       "      <td>169.787227</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>106.093023</td>\n",
       "      <td>61.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>150.045455</td>\n",
       "      <td>37.066667</td>\n",
       "      <td>91.714286</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>7.34800</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>351.063772</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age    DiasABP      FiO2        GCS Gender          HR      Height  \\\n",
       "1   42.0  59.543420  0.792857  15.000000      M  118.239130  169.787227   \n",
       "5   77.0  46.101449  0.454545   5.956522      M   79.269231  169.787227   \n",
       "6   60.0  57.753623  0.549199  13.333333      M   91.652174  175.300000   \n",
       "8   83.0  60.528090  0.496429  11.533333      F   79.078652  169.787227   \n",
       "16  59.0  76.250000  0.607143   9.454545      M   63.200000  169.787227   \n",
       "\n",
       "           K         MAP  NIDiasABP  ...      SysABP       Temp       Urine  \\\n",
       "1   3.625000   81.055075  79.000000  ...  118.591225  37.658333   89.729730   \n",
       "5   4.333333   72.217391  55.296296  ...  132.913043  36.466667  134.017937   \n",
       "6   4.050000   77.985507  58.260870  ...   99.014493  37.634694  290.625000   \n",
       "8   4.400000   86.505618  69.666667  ...  132.280899  36.716667  113.829787   \n",
       "16  4.150000  106.093023  61.833333  ...  150.045455  37.066667   91.714286   \n",
       "\n",
       "        Weight       pH    SAPS-I  SOFA  Length_of_stay    Survival  \\\n",
       "1   138.100000  7.43250  10.00000   5.0             7.0  351.063772   \n",
       "5   111.592208  7.46875  14.96168   9.0            11.0   10.000000   \n",
       "6    85.772059  7.39800  12.00000   0.0             6.0  351.063772   \n",
       "8    63.000000  7.33750  18.00000   7.0            10.0   88.000000   \n",
       "16   91.000000  7.34800  16.00000   9.0             6.0  351.063772   \n",
       "\n",
       "    In-hospital_death  \n",
       "1                 0.0  \n",
       "5                 1.0  \n",
       "6                 0.0  \n",
       "8                 0.0  \n",
       "16                0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have read in a table. The table is stored in a data structure called a dataframe. (But you only need to understand lists of lists to proceed with this tutorial.)\n",
    "\n",
    "Each row of the dataframe represents data for a single patient. Variables like `Age`, `Gender`, `HR`, `Height`, `PaCO2`, `PaO2`, `Temp`, and `Weight` are called *features*. We will use them as predictors. The very last column is called `In-hospital_death`, which indicates whether the patient survived (0) or died (1) in the ICU.\n",
    "\n",
    "While `Age`, `Gender`, `Height`, and `Weight` are self-explanatory demographic variables, the others are physiological measurements whose averages (from multiple measurements across time during the patients' stay in the ICU) have been recorded in the dataset. `Temp` is the body temperature, `HR` is the heart rate, `PaCO2` is the [partial pressure of arterial $CO_2$](https://en.wikipedia.org/wiki/PCO2), and `PaO2` is the [partial pressure of arterial $O_2$](https://en.wikipedia.org/wiki/Blood_gas_tension). \n",
    "\n",
    "We can see why these features could be important in predicting patient well-being. For example, decreasing body temperature [has been found](https://www.sciencedirect.com/science/article/abs/pii/S1071916408000675?via%3Dihub) to predict early rehospitalization for patients with congestive heart failure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wu9KGUZWnvCg"
   },
   "source": [
    "Gender is shown as 'M' for male and 'F' for female, but we would like for all variables to be numerical. You can use our function `label_encode` saved in `learningmachine.py` to do this. Understanding the inner workings of the functions in this file is not required for the tutorial. Recall that we imported `learningmachine` as `lm` previously, so in order to retrieve relevant functions, we use the `lm.function` notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "j3UvhDp1nvCj",
    "outputId": "3b92d7f8-5808-4473-f05c-b80a05fda7a1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>FiO2</th>\n",
       "      <th>GCS</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HR</th>\n",
       "      <th>Height</th>\n",
       "      <th>K</th>\n",
       "      <th>MAP</th>\n",
       "      <th>NIDiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Urine</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>SAPS-I</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Length_of_stay</th>\n",
       "      <th>Survival</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>59.543420</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>118.239130</td>\n",
       "      <td>169.787227</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>81.055075</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>118.591225</td>\n",
       "      <td>37.658333</td>\n",
       "      <td>89.729730</td>\n",
       "      <td>138.100000</td>\n",
       "      <td>7.43250</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>351.063772</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>46.101449</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>5.956522</td>\n",
       "      <td>1</td>\n",
       "      <td>79.269231</td>\n",
       "      <td>169.787227</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>72.217391</td>\n",
       "      <td>55.296296</td>\n",
       "      <td>...</td>\n",
       "      <td>132.913043</td>\n",
       "      <td>36.466667</td>\n",
       "      <td>134.017937</td>\n",
       "      <td>111.592208</td>\n",
       "      <td>7.46875</td>\n",
       "      <td>14.96168</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>57.753623</td>\n",
       "      <td>0.549199</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>91.652174</td>\n",
       "      <td>175.300000</td>\n",
       "      <td>4.050000</td>\n",
       "      <td>77.985507</td>\n",
       "      <td>58.260870</td>\n",
       "      <td>...</td>\n",
       "      <td>99.014493</td>\n",
       "      <td>37.634694</td>\n",
       "      <td>290.625000</td>\n",
       "      <td>85.772059</td>\n",
       "      <td>7.39800</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>351.063772</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>83.0</td>\n",
       "      <td>60.528090</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>11.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>79.078652</td>\n",
       "      <td>169.787227</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>86.505618</td>\n",
       "      <td>69.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>132.280899</td>\n",
       "      <td>36.716667</td>\n",
       "      <td>113.829787</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>7.33750</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>59.0</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>9.454545</td>\n",
       "      <td>1</td>\n",
       "      <td>63.200000</td>\n",
       "      <td>169.787227</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>106.093023</td>\n",
       "      <td>61.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>150.045455</td>\n",
       "      <td>37.066667</td>\n",
       "      <td>91.714286</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>7.34800</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>351.063772</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age    DiasABP      FiO2        GCS  Gender          HR      Height  \\\n",
       "1   42.0  59.543420  0.792857  15.000000       1  118.239130  169.787227   \n",
       "5   77.0  46.101449  0.454545   5.956522       1   79.269231  169.787227   \n",
       "6   60.0  57.753623  0.549199  13.333333       1   91.652174  175.300000   \n",
       "8   83.0  60.528090  0.496429  11.533333       0   79.078652  169.787227   \n",
       "16  59.0  76.250000  0.607143   9.454545       1   63.200000  169.787227   \n",
       "\n",
       "           K         MAP  NIDiasABP  ...      SysABP       Temp       Urine  \\\n",
       "1   3.625000   81.055075  79.000000  ...  118.591225  37.658333   89.729730   \n",
       "5   4.333333   72.217391  55.296296  ...  132.913043  36.466667  134.017937   \n",
       "6   4.050000   77.985507  58.260870  ...   99.014493  37.634694  290.625000   \n",
       "8   4.400000   86.505618  69.666667  ...  132.280899  36.716667  113.829787   \n",
       "16  4.150000  106.093023  61.833333  ...  150.045455  37.066667   91.714286   \n",
       "\n",
       "        Weight       pH    SAPS-I  SOFA  Length_of_stay    Survival  \\\n",
       "1   138.100000  7.43250  10.00000   5.0             7.0  351.063772   \n",
       "5   111.592208  7.46875  14.96168   9.0            11.0   10.000000   \n",
       "6    85.772059  7.39800  12.00000   0.0             6.0  351.063772   \n",
       "8    63.000000  7.33750  18.00000   7.0            10.0   88.000000   \n",
       "16   91.000000  7.34800  16.00000   9.0             6.0  351.063772   \n",
       "\n",
       "    In-hospital_death  \n",
       "1                 0.0  \n",
       "5                 1.0  \n",
       "6                 0.0  \n",
       "8                 0.0  \n",
       "16                0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.label_encode(df, 'Gender')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oAaU5XaKnvCl"
   },
   "source": [
    "`'M'` has been encoded as 1 and `'F'` has been encoded as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pg1y6IHsnvCm"
   },
   "source": [
    "From this point on, we will work with our data in the form of a list of lists, instead of as a dataframe. We will use a function called `df_to_lists`, which converts a dataframe to a list of lists. (Again, no need to understand the inner workings.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EonAR9UenvCp"
   },
   "source": [
    "We now convert our data into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hzT4cBYnvCp"
   },
   "outputs": [],
   "source": [
    "ICU_data = lm.df_to_list(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R0ui7v6bnvCr"
   },
   "source": [
    "Let's see what the first list (representing data for the first patient) within our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNuhIf8UnvCt",
    "outputId": "20b9a130-db7f-422d-d384-61130f6f80f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77.0,\n",
       " 54.2,\n",
       " 0.6714285714285714,\n",
       " 12.470588235294118,\n",
       " 0.0,\n",
       " 98.94202898550724,\n",
       " 152.4,\n",
       " 3.875,\n",
       " 73.4,\n",
       " 45.46153846153846,\n",
       " 144.75,\n",
       " 33.666666666666664,\n",
       " 116.0,\n",
       " 167.0,\n",
       " 140851.0,\n",
       " 105.13333333333334,\n",
       " 36.57272727272728,\n",
       " 98.14634146341464,\n",
       " 59.5,\n",
       " 7.36,\n",
       " 14.0,\n",
       " 3.0,\n",
       " 6.0,\n",
       " 3.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICU_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5YStF5IhnvCw"
   },
   "source": [
    "This is the data for the eleventh patient in the dataset (check to see that it's true!)\n",
    "\n",
    "In order for us to easily work with our new list, we'll use a function named `columnname_to_index` that displays the indices in our list that the column names in the original table correspond to. \n",
    "\n",
    "\n",
    "(Note to students: you don't need to understand the inner workings, but you do need to understand the structure that the function returns.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gukYMY7WnvC0"
   },
   "source": [
    "We'll now run this function on our table and store the output in `index_predictors_list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3qlGME0nvC1",
    "outputId": "9e2cf422-4af8-4454-ae29-3a938bfdfb1b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Age'),\n",
       " (1, 'DiasABP'),\n",
       " (2, 'FiO2'),\n",
       " (3, 'GCS'),\n",
       " (4, 'Gender'),\n",
       " (5, 'HR'),\n",
       " (6, 'Height'),\n",
       " (7, 'K'),\n",
       " (8, 'MAP'),\n",
       " (9, 'NIDiasABP'),\n",
       " (10, 'Na'),\n",
       " (11, 'PaCO2'),\n",
       " (12, 'PaO2'),\n",
       " (13, 'Platelets'),\n",
       " (14, 'RecordID'),\n",
       " (15, 'SysABP'),\n",
       " (16, 'Temp'),\n",
       " (17, 'Urine'),\n",
       " (18, 'Weight'),\n",
       " (19, 'pH'),\n",
       " (20, 'SAPS-I'),\n",
       " (21, 'SOFA'),\n",
       " (22, 'Length_of_stay'),\n",
       " (23, 'Survival'),\n",
       " (24, 'In-hospital_death')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_feature_list = lm.columnname_to_index(df)\n",
    "index_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84VrDTGVnvC5"
   },
   "source": [
    "From the list above, we can see that the feature 'Temp' is at index 16 within our list. Let's check it out for the eleventh patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LiS64gOonvC6",
    "outputId": "cd7ae666-7407-483e-8c2a-5b5cd6b97220"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.57272727272728"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICU_data[10][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KcWwUEk2nvC8"
   },
   "source": [
    "In order to make our code more readable and so that we don't have to look back at our `index_feature_list` to figure out the index at which a certain feature is located, we'll use another function named `feature_ind` that returns the index that corresponds to the feature name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ind(feat_name):\n",
    "    \"\"\"\n",
    "    Take feature name and return relevant index within list.\n",
    "    \"\"\"\n",
    "    for row in index_feature_list:\n",
    "        if feat_name == row[1]:\n",
    "            return row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-W7xvYW0nvC_"
   },
   "source": [
    "Let's make sure 'Temp' corresponds to index 16 as we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAY-3cOQnvC_",
    "outputId": "fe01f57e-4d30-474c-d6ea-7742de21e4df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ind('Temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1Bbv0HsnvDD"
   },
   "source": [
    "Now we'll use this function to find the eleventh patient's 'Temp'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yymjX1R3nvDE",
    "outputId": "bdf8e127-4cfb-46d7-acf7-55323f9f850c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.57272727272728"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICU_data[10][feature_ind('Temp')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the relationship between `Age` and `HR` (heart rate). We will build a function named `compute_avg_HR` to compute the average heart rate for each age based on sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_avg_HR(sex):\n",
    "    \"\"\"\n",
    "    Compute average heart rate for each unique age based on sex. Return list of relevant ages and list of average heart rates for each age.\n",
    "    \n",
    "    Keyword argument:\n",
    "    sex -- 0 or 1 for female or male, respectively\n",
    "    \"\"\"\n",
    "    ages = [x[feature_ind('Age')] for x in ICU_data]\n",
    "    unique_ages = list(set(ages))\n",
    "    HRs = []\n",
    "    rel_age = []\n",
    "    avg_HRs = []\n",
    "    \n",
    "    for age in unique_ages:\n",
    "        HRs.append([x[feature_ind('HR')] for x in ICU_data if x[feature_ind('Age')] == age and x[feature_ind('Gender')] == sex])\n",
    "        \n",
    "    for i, row in enumerate(HRs):\n",
    "        if len(row) != 0:\n",
    "            avg_HRs.append(sum(row)/len(row))\n",
    "            rel_age.append(unique_ages[i])      \n",
    "    return rel_age, avg_HRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then build a function named `plot_HR_age` to make a scatterplot with age on the x axis and average heart rate on the y axis. We can overlay the two scatterplots (one for female and one for male) on top of each other on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_HR_age(sex, str_sex):\n",
    "    \"\"\"\"\n",
    "    Plot heart rate versus average age based on sex.\n",
    "    \n",
    "    Keyword argument:\n",
    "    sex -- 0 or 1 for female or male, respectively\n",
    "    str_sex -- 'female' or 'male'\n",
    "    \"\"\"\n",
    "    plt.scatter(compute_avg_HR(sex)[0], compute_avg_HR(sex)[1], label = str_sex)\n",
    "    plt.title('Heart Rate vs Average Age')\n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel('Average Heart Rate')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_HR_age(1, 'male')\n",
    "plot_HR_age(0, 'female')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our scatterplots, we can see that as the age increases, the average heart rate tends decrease as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ac5s4BPOnvDH"
   },
   "source": [
    "Let's look more closely into our data, specifically focusing on the `In-hospital_death` outcome variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Xnw-qktnvDI",
    "outputId": "9c1ea9a0-f8db-4792-dba8-f030cdc11cb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = []\n",
    "for patient_data in ICU_data:\n",
    "    outcomes.append(patient_data[feature_ind('In-hospital_death')] )\n",
    "\n",
    "outcomes[:20] # the first 20 outcomes in the dataset\n",
    "set(outcomes) # What are the outcomes that we observe\n",
    "                     # in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6PU6QZAnvDK"
   },
   "source": [
    "We can see that the `In-hospital_death` variable for each patient contains only one of two outcomes: 0 or 1. If the patient died in the ICU, the outcome is 1 and if the patient survived, the outcome is 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4_L_GncnvDL"
   },
   "source": [
    "Let's extract data only for patients who died in the ICU by searching for data for which `In-hospital_death` is equal to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRE8iaSnnvDL"
   },
   "outputs": [],
   "source": [
    "patients_died = []\n",
    "for patient_data in ICU_data:\n",
    "    if patient_data[feature_ind('In-hospital_death')] == 1:\n",
    "        patients_died.append(patient_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOca8xnEnvDN"
   },
   "source": [
    "Let's see how many patients in our dataset died. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wu5ZPhXgnvDO",
    "outputId": "3e27b3c1-fbce-4a28-b4f8-781e4f731cbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "554"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patients_died)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fvj4BWConvDR"
   },
   "source": [
    "Let's do the same thing for patients that did not die in the ICU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X6NIdbhanvDS",
    "outputId": "9f9e447d-33ed-48f6-cc8c-444f6731a82f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients_lived = []\n",
    "for patient_data in ICU_data:\n",
    "    if patient_data[feature_ind('In-hospital_death')] == 0:\n",
    "        patients_lived.append(patient_data)\n",
    "        \n",
    "len(patients_lived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRpQADqcnvDU"
   },
   "source": [
    "We see that the number of patients that survived and the number of patients that died in our dataset are roughly equal. (The data was prepared so that the numbers are roughly equal by selecting a subset of all the patients; the majority of ICU patients at Beth Israel Deaconess do not die). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JBLF9_NBnvDX"
   },
   "source": [
    "### 3. Training/Validation/Test Split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4uYIYdnnvDY"
   },
   "source": [
    "We split our dataset into three separate sets: the training set, the validation set, and the test set. Each of the sets is used for a different purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vaAtvtonvDZ"
   },
   "source": [
    "<img src=\"Train_Valid_Test.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BB2C-HTonvDZ"
   },
   "source": [
    "**Training set:**  The input to the LM. The LM uses the training set to make the model. The LM uses patterns in the training set to make the model which tries to correctly predict the outcomes in the training set.\n",
    "\n",
    "**Validation set:** The validation set is used to tune the model: we can try different model settings, and pick the settings which result in a model that makes the most accurate predictions for the data in the validation set.\n",
    "\n",
    "**Test set:** This is the portion of our dataset that we use to evaluate how good the model will be at predicting outcomes for new data. The LM only \"sees\" the training set, and tries to make model's predictions match the outcomes in the training set. There is a danger that the model would work well on the training set, but not on new data. For that reason, we keep the test set separate from the training set -- the LM does not see the test set. We pretend the test set is new data, and compute the model's on it. This gives us an estimate for how well the model would predict the outcomes for new data.\n",
    "\n",
    "\n",
    "By default, you should put 70% of the data in the training set, 15% of the data in the validation set, and 15% of the data in the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqFAhL9lnvDb"
   },
   "source": [
    "Let's go ahead and generate our training, validation, and test sets from our `ICU_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVaUvqwnnvDf"
   },
   "source": [
    "To generate our three datasets, we'll randomly assign 70% of our data to the training set, 15% of our data to the validation set, and the remaining 15% of our data to the test set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Na7p8csDnvDg"
   },
   "outputs": [],
   "source": [
    "idx = list(range(len(ICU_data)))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "train_size = int(.7*len(ICU_data))\n",
    "valid_size = int(.15*len(ICU_data)) \n",
    "test_size = int(.15*len(ICU_data))\n",
    "\n",
    "train_dat = [ICU_data[i] for i in idx[:train_size]]\n",
    "valid_dat = [ICU_data[i] for i in idx[train_size+1:train_size+valid_size+1]]\n",
    "test_dat = [ICU_data[i] for i in idx[train_size+valid_size+2:train_size+valid_size+test_size+3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5LRW729OnvDi"
   },
   "source": [
    "Let's check out the lengths of our datasets to make sure they are in line with our split ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFBhYR76nvDj",
    "outputId": "01e288ad-9ab8-4b03-aa38-1f71b6256530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients in training set: 776\n",
      "Number of patients in validation set: 166\n",
      "Number of patients in test set: 165\n"
     ]
    }
   ],
   "source": [
    "print('Number of patients in training set:', len(train_dat))\n",
    "print('Number of patients in validation set:', len(valid_dat))\n",
    "print('Number of patients in test set:', len(test_dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OS_0bKk5nvDm"
   },
   "source": [
    "The LM requires us to provide the predictor variables and the outcome separately. Here is a function that takes in a dataset and produces a list of lists containing the predictor variable data and a list of lists containing the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpfA7Q2BnvDn"
   },
   "outputs": [],
   "source": [
    "def get_x_y_split(data, predictors):\n",
    "    \"\"\"\n",
    "    Split data into x and y components. \n",
    "    x will contain data corresponding to predictors of interest (specified in 'predictors' list).\n",
    "    y will contain data corresponding to outcome variable ('In-hospital_death').\n",
    "    \n",
    "    Keyword arguments:\n",
    "    data -- list of lists containing data \n",
    "    predictors -- list containing predictors of interest\n",
    "    \"\"\"    \n",
    "    feats_inds = []\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for feature in predictors:\n",
    "        feats_inds.append(feature_ind(feature))\n",
    "\n",
    "    for patient_data in data:\n",
    "        x.append([patient_data[i] for i in feats_inds])\n",
    "        y.append(patient_data[feature_ind('In-hospital_death')])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mKp1Q0xDnvDp"
   },
   "source": [
    "Now we'll use the function above to divide up each of our datasets into predictor and outcome components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVgfTswQnvDq"
   },
   "outputs": [],
   "source": [
    "# The predictor variables to be used to predict the outcome\n",
    "predictors = ['Age', 'Gender', 'HR', 'Height', 'PaCO2', 'PaO2', 'Temp', 'Weight']\n",
    "\n",
    "train_dat_x, train_dat_y = get_x_y_split(train_dat, predictors)\n",
    "valid_dat_x, valid_dat_y = get_x_y_split(valid_dat, predictors)\n",
    "test_dat_x, test_dat_y = get_x_y_split(test_dat, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-6ajjKcnvDx"
   },
   "source": [
    "Let's use our `learning_machine` to now build our model using our training set consisting of `train_dat_x` and `train_dat_y` generated above. We'll name the output of our function `my_model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2cgtDHuInvDx"
   },
   "outputs": [],
   "source": [
    "my_model = lm.learning_machine(train_dat_x, train_dat_y, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What goes on inside the Learning Machine (LM)?\n",
    "\n",
    "Let's get back to our Learning Machine.\n",
    "\n",
    "The LM looks for patterns in the data in order to make a model. **Logistic regression** is one possible learning machine that is suitable for predicting outcomes that are either 0 or 1. The output of Logistic regression can be the prediction (an integer: 0 or 1) or it can be the probability that the outcome is 1 (a probability is a real number between 0 and 1). If the output close to 1, the LM believes the outcome to be 1.\n",
    "\n",
    "In our ICU example, we are predicting whether the patient will die the ICU. Recall that 0 corresponds to \"Survived\" and 1 corresponds to \"Died\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8m8uwXtznvD-"
   },
   "source": [
    "### 3. The Predict Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xjn6gGo_nvD-"
   },
   "source": [
    "Now that our LM has generated a model for us after having learned the relationships in the data, we want to use our model to make predictions, given new data. Recall that since our LM only learned patterns from our training set, our validation set and test set can both constitute new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KdL--HBLnvD_"
   },
   "source": [
    "<img src=\"Predict.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZLGMPx2nvEA"
   },
   "source": [
    "We will now use the `predict` function, which takes in our model and new data as inputs. The output of the function will be a value between 0 and 1, representing the probability that the model believes the outcome will be 1. Let's go ahead and use `my_model` produced by the learning machine to make predictions, given our validation set. We'll assign the output of our `predict` function to `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xTBUvPPLnvED"
   },
   "outputs": [],
   "source": [
    "predictions = lm.predict(my_model, valid_dat_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the prediction for the 11-th patient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48997597666217585"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LqCPHgFnvEF"
   },
   "source": [
    "### 4. Correct Classification Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju6Je42JnvEG"
   },
   "source": [
    "After having made predictions using `predict`, we want to know how accurate our model was. To evaluate our model's performance, we can calculate what is called a correct classification rate (CCR) using the function `getCCR`. The CCR is computed by counting the number of correctly classified outcomes (correctly predicted a patient will die or correctly predicted a patient will survive) and dividing this number by the total number of predictions made. \n",
    "\n",
    "Let's build a function called `getCCR` to get this done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Clhj5VcnvEH"
   },
   "outputs": [],
   "source": [
    "def getCCR(model, x_data, y_data):\n",
    "    \"\"\"\n",
    "    Compute correct classification rate.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    x_data -- list of lists containing predictors \n",
    "    y_data -- list of lists containing outcome   \n",
    "    model -- model generated by the learning machine\n",
    "    \"\"\"\n",
    "    correctly_classified = 0\n",
    "\n",
    "    for i, outcome in enumerate(y_data):\n",
    "        pred = lm.predict(model, x_data)[i] > 0.5\n",
    "        if pred == outcome:\n",
    "            correctly_classified += 1\n",
    "    \n",
    "    return correctly_classified/len(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Gg5eysbnvEM"
   },
   "source": [
    "Let's check out our model's performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99HIa3RLnvEN",
    "outputId": "953be530-fae0-46d2-ef6f-9c04c704fd1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6385542168674698"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getCCR(my_model, valid_dat_x, valid_dat_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLTwDnkmnvEQ"
   },
   "source": [
    "It looks like around 64.5% of the model's predictions were correct (on the validation set -- you can compute the CCR on the training set, but it's not as interesting; it is not impressive if a model can correctly predict the outcomes for patients the model has been trained with.) We observe performance that is higher than 50%. This is better than tossing a fair coin. That means that the model predicts something meaningful. (Note that if, for example, 90% of patients survived and 10% died, a 65% CCR would be very unimpressive -- we could do better by simply predicting \"survived\" for every patient. But in our dataset, where about 50% of the patients survived and 50% died, a 65% CCR means the model can be useful. The proportion of the plurality outcome is called the *base rate*).\n",
    "\n",
    "Let's make a function that computes the base rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_gx9qiLnvEQ"
   },
   "outputs": [],
   "source": [
    "def getBaseRate(y_data):\n",
    "    \"\"\"\n",
    "    Compute base rate.\n",
    "\n",
    "    Keyword arguments:\n",
    "    y_data -- list of lists containing outcome    \n",
    "    \"\"\"\n",
    "    return sum(y_data) / len(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2nz7C3idnvET"
   },
   "source": [
    "Let's find the base rate for our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feU7-i8dnvEU",
    "outputId": "e37e828c-6d8c-4389-8c8c-aaa750032578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5421686746987951"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getBaseRate(valid_dat_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9w0ZlNjfnvEb"
   },
   "source": [
    "We see that our model's performance is around 10.2% higher than the base rate. The smaller this difference (the closer our CCR is to the base rate), the worse our model is at making predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mUFzqLwYnvDV"
   },
   "source": [
    "\n",
    "\n",
    "#### More on Logistic Regression (optional)\n",
    "\n",
    "Logistic regression computes a \"rating\" for each patient in the dataset. The larger the rating, the larger the probability of the outcome's being 1 according to the logistic regression.\n",
    "\n",
    "In our model, we will use following as predictors: `Age`, `Gender`, `HR`, `Height`, `PaCO2`, `PaO2`, `Temp`, and `Weight`. We will also need our outcome variable: `In-hospital_death`. The rating is computed as follows.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnaVZSWinvDW"
   },
   "source": [
    "$$Rating = \\beta_0 + \\beta_1Age + \\beta_2Gender + \\beta_3HR + \\beta_4Height + \\beta_5PaCO_2 + \\beta_6PaO_2 + \\beta_7Temp + \\beta_8Weight$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CYK1TfEGnvDW"
   },
   "source": [
    "Each predictor variable is multiplied by different coefficients represented by $\\beta$s. If the LM thinks that a certain predictor is more predictive of the outcome, it will assign a higher coefficient to it, effectively giving it more weight in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-NaYNOZnvDX"
   },
   "source": [
    "Before we start building our model based on the `ICU_data`, we'll walk through splitting our dataset into the training set, validation set, and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.coefs` will show us the model's coefficients. Recall from earlier in this tutorial that the logistic regression algorithm calculates a rating based on a weighted sum. Each predictor is weighted by a certain coefficient that indicates the predictive degree of the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgnSw6XznvD1",
    "outputId": "57404553-2204-4b97-bcfb-5a8dc3d6f9a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', 0.03298076267856131),\n",
       " ('Gender', 0.1609301160957725),\n",
       " ('HR', 0.02569835964092494),\n",
       " ('Height', -0.008967682024184341),\n",
       " ('PaCO2', -0.03112803398475024),\n",
       " ('PaO2', -0.004118490319768773),\n",
       " ('Temp', -0.03748239631997881),\n",
       " ('Weight', -0.00011714197817034553)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSyuM6RjnvD9"
   },
   "source": [
    "A positive coefficient means the model believes there is a positive correlation between the feature and an outcome of 1 (dying in the ICU). A negative coefficient means the model believes there is a negative correlation between the feature and an outcome of 1. Note that we cannot directly compare the coefficients assigned to the various features because they have not been normalized. *Normalization* is a technique used in data preparation to change the values of variables to a common scale so that they could be compared. We will skip this process in this tutorial for the sake of simplicity. For now, what we can say is how each predictor seems to be affecting model's prediction. For example, from the coefficients generated above, we can say that an increase in 'Age' of 1 year would increase the score (weighted sum) by about 0.0335, making it more likely for the model to predict that the patient will die."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mUFzqLwYnvDV",
    "8m8uwXtznvD-",
    "4LqCPHgFnvEF"
   ],
   "name": "PredictiveModelingTutorial_Fresh (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
